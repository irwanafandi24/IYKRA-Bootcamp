# -*- coding: utf-8 -*-
"""IYKRA Week 4 - Customer Segmentation and Market Basket Analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KcAbxmTuNAyU_0FnM826xXjKTLxCo_SW
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from mlxtend.frequent_patterns import apriori
from mlxtend.frequent_patterns import association_rules
sns.set()

#https://www.kaggle.com/mgmarques/customer-segmentation-and-market-basket-analysis/data
df = pd. read_excel('Online Retail.xlsx');

df.head()

df.info()

df.shape

df.describe()

"""# Preprocessing

## Check the customer in every country
"""

customer_count = df[['CustomerID', 'Country']].drop_duplicates()
customer_count = customer_count.groupby(['Country'])['CustomerID'].aggregate('count').reset_index().sort_values('CustomerID', ascending=False)

plt.figure(figsize=(15,7))
ax = sns.barplot(x=customer_count['Country'], y=customer_count['CustomerID'])
ax.set_xticklabels(ax.get_xticklabels(), rotation=90)

for p in ax.patches:
    ax.annotate(str(int(p.get_height())), (p.get_x() * 1.005, p.get_height() * 1.005))
plt.ylabel('Frequency')
plt.title('The Total Number of Transactions per Country', fontsize=16)
plt.show()

"""### Data Clean Up (Choose country with the most customer)
- Get the customer data only from UK
- Remove data with null customer ID
- Remove the data with minus quantity value
"""

df[df['Quantity']<0].head()

#there isn't relation between the negative data, so I decide to delete the negative data
df.iloc[234:237]

#select the UK data
df = df[df['Country'] == 'United Kingdom']
#remove the data with null customer ID
df = df[pd.notnull(df['CustomerID'])]
#remove data with negative quantitiy
df = df[df['Quantity']>0]

df.describe()

"""# Customer Segmentation

## RFM
- Recency (R): check the earliest and the latest date of the transaction, then asssign the latest date to calculate transaction rescency.
- Frequency (F) : the number of invoices per costomer
- Monetary (M): how much they spend their money for our product
<p>Use scale 1-4 to determine the value of RFM (1 indicate high and 4 indicate low, u kan use quantile)
<p>Then concat RFM Score. Example 113</p>

<b>First, create total price feature</b>
"""

df['TotalPrice'] = df['Quantity']*df['UnitPrice']

"""<b>Check the earliest and latest date of the transaction</b>"""

print("Min Date: ",df['InvoiceDate'].min()," | Max Date: ", df['InvoiceDate'].max())

import datetime as dt
# now = dt.date(2011,12,10)
now = np.datetime64('2011-12-10')
df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])

"""<b>RFM Table</b>"""

rfm = df.groupby('CustomerID').agg({'InvoiceDate' : lambda x: (now-x.max()).days,
                                    'InvoiceNo': lambda x : len(x),
                                    'TotalPrice': lambda x : x.sum()})
rfm.rename(columns={'InvoiceDate': 'recency','InvoiceNo': 'frequency', 'TotalPrice': 'monetary_value'}, inplace=True)
rfm.head()

"""## Get the rfm value"""

quantiles = rfm.quantile(q=[0.25,0.5,0.75])
quantiles

quantil_dict = quantiles.to_dict()

rfm_segmented = rfm

# 1 is better then 4
# if the different between now and latest date is much, mean bad
def RecencyScore(x,p,d):
  if x <= d[p][0.25]:
    return 1
  elif x <= d[p][0.5]:
    return 2
  elif x <= d[p][0.75]:
    return 3
  else:
    return 4
# more spend better
def MonetaryScore (x,p,d):
  if x <= d[p][0.25]:
    return 4
  elif x <= d[p][0.5]:
    return 3
  elif x <= d[p][0.75]:
    return 2
  else:
    return 1

rfm['R'] = rfm['recency'].apply(RecencyScore, args=('recency', quantiles))
rfm['F'] = rfm['frequency'].apply(MonetaryScore, args=('frequency', quantiles))
rfm['M'] = rfm['monetary_value'].apply(MonetaryScore, args=('monetary_value', quantiles))
rfm.head()

rfm['RFMtotal'] = rfm.R+rfm.F+rfm.M
rfm['RFMScore'] = rfm.R.map(str)+rfm.F.map(str)+rfm.M.map(str)
rfm['RFMScore'] = rfm['RFMScore'].astype(int)
rfm.head()

rfm.info()

"""## KMeans"""

# from customerSegments import loyal_customers, big_spenders, lost_customers, bad_spenders

# rfm_try = rfm.copy()

# score_labels = ['Green', 'Bronze', 'Silver', 'Gold']
# score_groups = pd.qcut(rfm_try.RFMScore, q = 4, labels = score_labels)
# rfm_try['RFM_Level'] = score_groups.values
# rfm_try = rfm_try.sort_values(by='RFMScore', ascending=False)
# rfm_try.head()

# rfm_try.RFM_Level.value_counts()

# rfm_try.iloc[975:985]

#https://www.kaggle.com/tklimonova/online-retail-cohort-and-rfm-analysis
#https://retail.aspiresys.com/customer-segmentation-using-rfm-analysis-demo?elqTrackId=23942feb0d1a4dcf908a23515a20947f&elq=00000000000000000000000000000000&elqaid=1115&elqat=2&elqCampaignId=

rfm.head()
rfm2 = rfm.copy()
rfm3 = rfm.copy()
rfm4 = rfm.copy()

feature2 = rfm[['F','M']]
feature3 = rfm[['R','F','M']]
feature4 = rfm[['R','F','M','RFMScore']]

"""### Kmeans using  Frequency and Monetary"""

feature2.head()

plt.scatter(feature2['F'], feature2['M'])

from sklearn.cluster import KMeans
wcss = []
for i in range (2,11):
    kmeans = KMeans(i)
    kmeans.fit(feature2)
    wcss.append(kmeans.inertia_)

#plot the elbow
clstr = range(2,11)
plt.figure(figsize=(15,7))
plt.scatter(clstr, wcss)
plt.plot(clstr,wcss, color='orange')
plt.xlabel("The number of Clusters")
plt.ylabel("Within-cluster sum of square")
plt.show()

kmeans = KMeans(5)
kmeans.fit(feature2)
label = kmeans.predict(feature2)
rfm2['Label'] = label
rfm2.head()

plt.scatter(feature2['F'], feature2['M'], c=rfm2['Label'], cmap='rainbow')
plt.xlabel('F')
plt.ylabel('M')
plt.title('Transaction Cluster')
plt.show()

"""### Kmeans using  Recency, Frequency, and Monetary"""

from sklearn.cluster import KMeans
wcss = []
for i in range (2,11):
    kmeans = KMeans(i)
    kmeans.fit(feature3)
    wcss.append(kmeans.inertia_)

#plot the elbow
clstr = range(2,11)
plt.figure(figsize=(15,7))
plt.scatter(clstr, wcss)
plt.plot(clstr,wcss, color='orange')
plt.xlabel("The number of Clusters")
plt.ylabel("Within-cluster sum of square")
plt.show()

kmeans = KMeans(4)
kmeans.fit(feature3)
label = kmeans.predict(feature3)
rfm3['Label'] = label
rfm3.head()

rfm3['Label'].value_counts()

"""### Kmeans using Recency, Frequency, Monetary, and FRMScore"""

from sklearn.cluster import KMeans
wcss = []
for i in range (2,11):
    kmeans = KMeans(i)
    kmeans.fit(feature4)
    wcss.append(kmeans.inertia_)

#plot the elbow
clstr = range(2,11)
plt.figure(figsize=(15,7))
plt.scatter(clstr, wcss)
plt.plot(clstr,wcss, color='orange')
plt.xlabel("The number of Clusters")
plt.ylabel("Within-cluster sum of square")
plt.show()

kmeans = KMeans(4)
kmeans.fit(feature4)
label = kmeans.predict(feature4)
rfm4['Label'] = label
rfm4.head()

rfm4.sort_values(by='Label', ascending=False)

"""<b>See the data characteristic by filter the label one by one</b>"""

rfm4[rfm4['Label']==0].head()

rfm4[rfm4['Label']==1].head()

rfm4[rfm4['Label']==2].head()

rfm4[rfm4['Label']==3].head()

rfm4['Label'].value_counts()

"""# Market Basket Analysis"""

dfm = pd. read_excel('Online Retail.xlsx');

dfm['Description'] = dfm['Description'].str.strip() #remove white space in string
dfm.dropna(axis=0, subset=['InvoiceNo'], inplace=True)
dfm['InvoiceNo'] = dfm['InvoiceNo'].astype('str')
dfm = dfm[~dfm['InvoiceNo'].str.contains('C')] #filter invoice no and return invoice that doesn't containt C
dfm =dfm[pd.notnull(dfm['CustomerID'])] #filter data where the customerID not null
dfm = dfm[dfm['Quantity']>0] #just select the data with quantity > 0
dfm.describe()

basket = (dfm[dfm['Country']== 'United Kingdom'].groupby(['InvoiceNo', 'Description'])['Quantity'].sum()
          .unstack().reset_index().fillna(0)
          .set_index('InvoiceNo'))
basket.head()

#get relations
def encode_units(x):
    return 0 if x <= 0 else 1

basket_sets = basket.applymap(encode_units)
basket_sets.drop('POSTAGE', inplace=True, axis=1) #remove postage as an items
basket_sets.head()

"""## train the model"""

# Generating Frequent Items
frequent_itemset = apriori(basket_sets, min_support=0.02, use_colnames=True)
frequent_itemset.head(20)

#generate rules
rules = association_rules(frequent_itemset, metric="lift", min_threshold=1)

#https://infocenter.informationbuilders.com/wf80/index.jsp?topic=%2Fpubdocs%2FRStat16%2Fsource%2Ftopic49.htm
rules.head(100)

"""## Makeing Recomendation System"""

#filter rule
rules[(rules['lift']>20)&(rules['confidence']>0.8)]

basket_sets['PINK REGENCY TEACUP AND SAUCER'].sum()

basket_sets['GREEN REGENCY TEACUP AND SAUCER'].sum()

